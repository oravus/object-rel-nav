# required paths
path_dataset: './data/' # symlink different datasets within this folder
path_models: ''
path_results: './out/results/' # output folder for results

# episode/task settings
start_idx: 0 # start index for episodes
step_idx: 3 # step index for episodes
end_idx: 108 # end index for episodes

reverse: False # Ignore
task_type: "original" # from ["original", "alt_goal", "via_alt_goal"] corresponding to ["Imitate", "AltGoal", "Shortcut"] tasks in the ObjectReact paper. For the reverse task, set reverse True for task_type original. 
use_gt_localization: True # if True, oracle decides the localizedImgIdx
env: "sim" # TODO: include "real"

split: "val"
threshold_goal_distance: 1.0 # evaluation threshold for success
max_start_distance: "hard" # from ["easy", "hard", "full"] to decide trajectory length of the mapping run
max_steps: 250 # max number of steps for an agent in an episode

exp_name: "gt_metric_robohop" # unique name for the experiment

# running from list of winners or failure or no good
run_list: '' #'winners'  #  ['', 'winners', 'failures', 'no_good']
path_run: ''

# controller and mapping params
method: 'robohop' # select controller from ['robohop', 'tango', 'pixnav']
segmentor: 'fast_sam'
goal_source: 'gt_metric' # from [gt_metric, gt_topological, topological] to select how the goal is generated (see Tango paper)
graph_filename: null # Ignore
infer_depth: True # use depth_anything instead of sim_depth
infer_traversable: True # use fast_sam + CLIP instead of sim instances 

# logging and display
log_wandb: False
log_robot: True # Tango's output logging
debug: False
except_exit: False # set True to disable try/except, print traceback, & exit

# tango's visualization panel
plot: False
save_vis: False
# dump_episode_images: 0

cull_qry_instances: False # Ignore
cull_map_instances: False # Remove specific categories (e.g., "floor", "ceiling") from the map graph

sim:
  hfov: 120
  width: 320
  height: 240
  sensor_height: 0.4 # [0.4, 1.31, 1.5]
  sensor_height_map: 1.31 # [0.4, 1.31, 1.5]

goal_gen:
  textLabels: [] # ["floor", "ceiling", "ground"] # from [[], <list of labels to remove>

  # segmentor
  map_segmentor_name: "fast_sam" # used during mapping [fast_sam, sam21]

  # matcher
  matcher_name: "lightglue" # used during loc [lightglue, sam2 ...]
  map_matcher_name: "lightglue" # used during mapping [lightglue, sam2]
  geometric_verification: True # this has no effect if matcher_name is lightglue
  match_area: False

  # planner
  edge_weight_str: "margin" # ["margin", "geodesic_(max,min,avg)", "e3d", null (=None in python)]
  goalNodeIdx: null # used to set specific index for real-world experiments
  use_goal_nbrs: True # use goal node's neighbor nodes from the same image as well during planning
  plan_da_nbrs: True # include goal node's neighbors based on data association (da) 
  preplan_to_goals_only: False # to save storage & time, precompute paths to goal nodes only
  rewrite_graph_with_allPathLengths: False

  # localizer
  loc_radius: 4
  subsample_ref: 1 # skip every nth reference image
  reloc_rad_add: 2 
  reloc_rad_max: 15
  min_num_matches: 0 # threshold on num matches to decide if robot is lost/localized

  # tracker
  do_track: False

controller:
  config_file: "configs/controller/object_react_controller.yaml"
  # following only used with real_remote
  v_min: 0.05
  v_max: 0.2
  w_min: -0.3
  w_max: 0.3

# CoRL2025 specific
episode_blacklists:
  all_tasks: [
    'CrMo8WxCyVb_0000016_chair_411_',
    'LT9Jq6dN3Ea_0000000_tv_monitor_21_',
    'Nfvxx8J5NCo_0000009_bed_267_',
    'k1cupFYWXJ6_0000000_sofa_19_',
    'k1cupFYWXJ6_0000008_chair_594_',
    'VBzV5z6i1WS_0000000_tv_monitor_43_',
  ]
  original: []
  original_reverse: [
    # Goal is full frame:
    "GLAQ4DNUx5U_0000000_plant_22_",
    # Goal is incorrect:
    "6s7QHgap2fW_0000000_tv_monitor_34_",
    # Could not find a valid start state:
    "svBbv1Pavdk_0000000_plant_7_",
    # Entire floor of a room is the goal (already globally ignored):
    "LT9Jq6dN3Ea_0000000_tv_monitor_21_",
  ]
  alt_goal_v2: [
    "5cdEh9F2hJL_0000000_toilet_36_",
    "7MXmsvcQjpJ_0000000_chair_16_",
    "CrMo8WxCyVb_0000000_toilet_33_",
    "DYehNKdT76V_0000000_toilet_115_",
    "TEEsavR23oF_0000000_tv_monitor_10_",
    "VBzV5z6i1WS_0000000_tv_monitor_43_",
    "XB4GS9ShBRE_0000000_tv_monitor_8_",
    "a8BtkwhxdRV_0000000_toilet_18_",
    "q3zU7Yy5E5s_0000000_bed_23_",
    # Agent reaches goal, but cannot succeed due to goal height/obstacles:
    "Dd4bFSTQ8gi_0000000_sofa_9_",
    # Goal is in a different room that would barely be visible to any agent:
    "qyAac8rV8Zk_0000000_tv_monitor_8_",
  ]
  via_alt_goal: [
    # Goal is large sofa, which can be reached but still fail if on the wrong side:
    "BAbdmeyTvMZ_0000000_chair_68_",
    # Start of episode presents a see-through wall:
    "MHPLjHsuG27_0000000_tv_monitor_17_",
    # Missing agent_states.npy:
    "a8BtkwhxdRV_0000000_toilet_18_",
    # Non-traversible area on way to goal:
    "cvZr5TUy5C5_0000000_chair_31_",
    # Start faces a wall at a dead end:
    "yr17PDCnDDW_0000000_plant_32_",
    # Alt goal is on the way:
    "5cdEh9F2hJL_0000000_toilet_36_",
    "Dd4bFSTQ8gi_0000000_sofa_9_",
  ]
